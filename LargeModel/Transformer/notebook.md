# 1. 编解码

## 1.1 前言

在Transformer中，注意力机制虽然特别，但理解Transformer的关键是编码和解码结构。编解码和注意力机制的关系可以类比于计算机中的冯诺依曼架构和显卡：

- 编解码：Transformer能够运行的基本原理。
- 注意力机制：显卡→在冯诺依曼这个大框架中，为了满足某种特定的任务而做出针对性优化的结构。

## 1.2 大模型路径

<a></a>
<div align=center>
    <img src=./imgs_markdown/2024-08-05-17-06-21.png
    width=100%></br><center>大模型进化图</center>
</div>

上图的大模型进化图中有三条路线：

|       路线        |     代表大模型     | 特点                              | 强项                 |
| :---------------: | :----------------: | :-------------------------------- | :------------------- |
|  `Encoder-Only`   |       `BERT`       | 只保留了Transformer中编码器部分   | 学习和理解语言的内容 |
| `Encoder-Decoder` |       `UL2`        | 保留了Transformer中编码器和解码器 | 实际应用价值不高     |
|  `Decoder-Only`   | `ChatGPT`、`LLaMA` | 只保留了Transformer中解码器部分   | 生成内容             |

🤔 𝑸𝒖𝒆𝒔𝒕𝒊𝒐𝒏：为什么会有这三种路线呢？
🥳 𝑨𝒏𝒔𝒘𝒆𝒓：要想搞明白这个问题，我们需要搞清楚一件事情，所谓的编解码中的`码`到底是什么。

## 1.3 编码

### 1.3.1 前言

假设我们想要让LLM实现一个英译汉和汉译英的功能，那么对于一个词在两种语言的上下文关系是类似的。香蕉这个词，不管是在中文语境还是在英文语境中，它的上下文里面应该总是和『猴子』『黄色』『甜』『水果』这样的词有着更加紧密的联系。前面说的编解码中的『码』就是指<font color='red'><b>把各种语言里面中符号、发音等形式上的不同剥离掉之后，剩下来单纯的语义关系</b></font>。

<kbd>🤔 𝑸𝒖𝒆𝒔𝒕𝒊𝒐𝒏</kbd>：那么这个表示单纯语义信息的『码』应该怎么设计呢？
<kbd>🥳 𝑨𝒏𝒔𝒘𝒆𝒓</kbd>：第一，由于LLM训练是在计算机中的，所以肯定要进行数字化。第二，因为这个『码』需要表示语义之间的相互关系，所以这个『码』数字化之后的数值可以体现出语义之间的关系才行。

那么应该如何设计这个『码』呢？在机器学习中有两个经典的环节可以启发我们：

1. `tokenizer`：标记器、分词器
2. `one-hot`：独热编码

上面的两个模块都可以对文本中最基础的语义单元进行数字化。

🤔 𝑸𝒖𝒆𝒔𝒕𝒊𝒐𝒏：最基础的语义单元是什么？
🥳 𝑨𝒏𝒔𝒘𝒆𝒓：有很多策略：①字母；②单词；③介于字母和单词之间的词根。对应中文来说：①字；②词

> 这里的『最基础的语义单元』其实就是TOKEN。

那么我们就知道了，`tokenizer`和`one-hot`分别在利用不同的策略对Token实施数字化。

🤔 𝑸𝒖𝒆𝒔𝒕𝒊𝒐𝒏：既然`tokenizer`和`one-hot`都可以对Token进行数字化，那么我们要使用哪种呢？
🥳 𝑨𝒏𝒔𝒘𝒆𝒓：我们先看一下这两种方式是如何对Token进行数字化的：

- `tokenizer`对Token实施数字化的方法比较简单，就是给每一个Token分配一个独立的ID。那么`tokenizer`会把所有的Token都投射到一根一维的数轴上。
- `one-hot`会把二进制中的每一位对应一个Token。如果有『苹果』『香蕉』『梨』这三个Token，那么会生成：
  - `001`代表『苹果』
  - `010`代表『香蕉』
  - `100`代表『梨』

<a></a>
<div align=center>
    <img src=./imgs_markdown/2024-08-05-17-32-00.png
    width=30%></br><center>tokenizer和one-hot对Token数字化的示意图</center>
</div>

`tokenizer`和`one-hot`代表了对Token进行数字化的两种极端：
- `tokenizer`是把所有Token投射到了一个一维空间（不管Token有多少个）
- `one-hot`则是为每一个Token都分配了一个单独的维度，最终就会生成一个『有多少Token就有多少维度的高维空间』

我们可以看到，不管是`tokenizer`还是`one-hot`都可以很好地对Token进行数字化，但是我们在前面也提到了，数字化之后的数值可以体现出语义之间的关系才行。那么`tokenizer`和`one-hot`都可以满足这个要求吗？

### 1.3.2 tokenizer的问题

`tokenizer`把所有的Token都投射到了一个一维空间上，这就导致这个空间的信息过于密集，从而很难表达出一些复杂的语义。举个例子：

- `1`表示『苹果』
- `2`表示『香蕉』
- `3`表示『梨』

这三个Token都是水果，那么它们对应的数值比较接近，看起来`tokenizer`是比较合理的，但是如果『苹果』这个Token表示的不是水果而是手机呢？那么『苹果』放在这里就不合适了，很难体现出相邻数值之间关联性较高的要求。再者，对于『苹果和香蕉』这样一个组合起来的语义，按照直觉，应该是两种语义加起来，即`1+2`，但是`3`这个数值已经被『梨』占用了，这就会发生冲突。

### 1.3.3 one-hot的问题

与`tokenizer`的问题相反，`one-hot`因为要给每一个Token都分配一个单独的维度，因此如果Token太多，那么生成的空间维度太高了，这就导致信息密度过于稀疏。但是`one-hot`也有好处，就是它可以很容易的表示出『苹果和香蕉』这样的组合语义。

- `001`代表『苹果』
- `010`代表『香蕉』
- `100`代表『梨』

那么『苹果和香蕉』的`one-hot`编码就是`011`。虽然但是，`one-hot`最大的问题还是维度空间太大了，而且所有的Token相互正交且模长都是1，这就会导致所有向量之间的内积永远是0，很难体现出Token之间的语义联系。而且由于模长都是1，所有Token之间语义关系全部都是靠维度之间的关系去体现的，并没有充分把空间的长度利用起来。

### 1.3.3 tokenizer和one-hot缺点总结

- `tokenizer`：把所有的语义信息都变成了长度问题，完全没有利用维度关系去表示语义信息。
- `one-hot`：①维度空间太大了；②所有Token之间语义关系全部都是靠维度之间的关系去体现的，并没有充分把空间的长度利用起来。

### 1.3.4 改进方式

既然`tokenizer`和`one-hot`是两个极端，那么为了解决二者存在的问题，那么我们可以找一个维度高，但比`one-hot`要低的空间，去协助完成编码和解码的工作。这个空间一般称之为『潜空间』。

那么我们怎么才能找到这个『潜空间』呢？一般有两个大的方向：

1. 基于`tokenizer`分词后的ID去升维
2. 基于`one-hot`编码后去降维

这两个方向各有优劣，但从直觉上出发，把一个东西降维相比升维还是更加简单的。可以这么想，一种是把原数据进行压缩，一种是把压缩后的数据还原，怎么想也是压缩数据相对容易一些。

# 2. 矩阵和空间变换基础

提到降维，这里有一种新颖的东西：在线性代数中，向量和一个矩阵相乘就可以理解为是一种空间变换。

<a></a>
<div align=center>
    <img src=./imgs_markdown/2024-08-05-19-53-21.png
    width=20%></br><center>向量和矩阵的乘法</center>
</div>

上图中展示了『向量和矩阵的乘法』，这张图我们应该都熟悉，即向量里的每一个元素都会和矩阵中每一列相乘、相加，最后得到一个数值（新向量的一个值）。这种理解方式是从『代数』的角度出发的，那么我们是否可以使用『几何』的角度来<font color='red'><b>直观地</b></font>理解这个运算呢？

<a></a>
<div align=center>
    <img src=./imgs_markdown/2024-08-05-19-56-53.png
    width=30%></br><center>向量与矩阵乘法的代数理解示意图：向量</center>
</div>

假设$T$向量就是与矩阵相乘的向量，$T$向量中的每一个数值就是这个向量在对应坐标系下的坐标值。在图中，也就是$T$向量在$\vec{e_1}$和$\vec{e_2}$这个标准正交基上的分量，分量值分别是$a\vec{e_1}$和$b\vec{e_2}$。那么这个向量和矩阵相乘之后，它变成了如下图所示的样子：

<a></a>
<div align=center>
    <img src=./imgs_markdown/2024-08-05-20-20-28.png
    width=30%></br><center>向量与矩阵乘法的代数理解示意图：结果</center>
</div>

我们可以看到，向量$T$变成了一个新的坐标系下表示。在新的坐标系下，它的坐标轴从原来的$\vec{e_1}$和$\vec{e_2}$这个标准正交基上的分量变成了$\vec{e'_1}$和$\vec{e'_2}$。现在我们要看的是，怎么把向量$T$在之前红色的坐标系下变成绿色的坐标系。

我们可以想一下，向量$T$其实在坐标系变换过程中并不重要，重要的是坐标系互相之间的关系，那么这种关系本质上就是坐标轴互相之间的关系，而坐标轴可以看成是一个单位向量。

如下图左边所示，假设$\vec{e_1}$在新坐标系下，三个坐标轴的分量分别是$w_{1,1}$、$w_{1,2}$、$w_{1,3}$，那么向量$T$在新坐标系下可以用$a\vec{e_1}=(aw_{1,1}, aw_{1,2}, aw_{1,3})$来表示。原来的$T$在红色坐标系下是有两个分量的，在新坐标系下我们也不能忘了它另外一个分量，如下图的右图所示，第二个分量的坐标轴从原来的$(1, 1, 1)$变成了$(w_{2,1}, w_{2,2}, w_{2,3})$，那么具体的分量可以在新坐标系下表示为：$b\vec{e_2}=(bw_{2,1}, bw_{2,2}, bw_{2,3})$。



# 3. 神经网络基础

# 4. 词嵌入

# 5. Word2Vec

# 6. 注意力

# 7. 理解Q和V

# 8. 交叉注意力

# 9. 位置编码

# 10. 多头注意力

# 11. 掩码


# 知识来源

1. [从编解码和词嵌入开始，一步一步理解Transformer，注意力机制(Attention)的本质是卷积神经网络(CNN)](https://www.bilibili.com/video/BV1XH4y1T76e)